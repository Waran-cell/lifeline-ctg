{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeEyeZIEz5Dc",
        "outputId": "ffa3899b-a456-4cd3-ea6f-1a1d6d20a8e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.8.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Requirement already satisfied: imbalanced-ensemble in /usr/local/lib/python3.12/dist-packages (0.2.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-ensemble) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from imbalanced-ensemble) (1.16.2)\n",
            "Requirement already satisfied: pandas>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from imbalanced-ensemble) (2.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from imbalanced-ensemble) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn==1.6.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-ensemble) (1.6.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-ensemble) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-ensemble) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.50.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-ensemble) (4.67.1)\n",
            "Requirement already satisfied: openml>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-ensemble) (0.15.1)\n",
            "Requirement already satisfied: platformdirs>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-ensemble) (4.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.6.0->imbalanced-ensemble) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.2->imbalanced-ensemble) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.2->imbalanced-ensemble) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.2->imbalanced-ensemble) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.2->imbalanced-ensemble) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.2->imbalanced-ensemble) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.2->imbalanced-ensemble) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.2->imbalanced-ensemble) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.2->imbalanced-ensemble) (2.9.0.post0)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from openml>=0.14.0->imbalanced-ensemble) (2.5.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.12/dist-packages (from openml>=0.14.0->imbalanced-ensemble) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from openml>=0.14.0->imbalanced-ensemble) (2.32.4)\n",
            "Requirement already satisfied: minio in /usr/local/lib/python3.12/dist-packages (from openml>=0.14.0->imbalanced-ensemble) (7.2.18)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from openml>=0.14.0->imbalanced-ensemble) (18.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.1->imbalanced-ensemble) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.1->imbalanced-ensemble) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.2->imbalanced-ensemble) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from minio->openml>=0.14.0->imbalanced-ensemble) (25.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from minio->openml>=0.14.0->imbalanced-ensemble) (2025.8.3)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.12/dist-packages (from minio->openml>=0.14.0->imbalanced-ensemble) (3.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from minio->openml>=0.14.0->imbalanced-ensemble) (4.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from minio->openml>=0.14.0->imbalanced-ensemble) (2.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->openml>=0.14.0->imbalanced-ensemble) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->openml>=0.14.0->imbalanced-ensemble) (3.10)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->minio->openml>=0.14.0->imbalanced-ensemble) (25.1.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml>=0.14.0->imbalanced-ensemble) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml>=0.14.0->imbalanced-ensemble) (2.23)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.2)\n",
            "Requirement already satisfied: pytorch_tabnet in /usr/local/lib/python3.12/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabnet) (2.0.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabnet) (1.6.0)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabnet) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabnet) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.12/dist-packages (from pytorch_tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch_tabnet) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.3->pytorch_tabnet) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo\n",
        "!pip install imbalanced-ensemble\n",
        "!pip install lightgbm\n",
        "!pip install pytorch_tabnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KHwJ97oz-uh",
        "outputId": "dcd1e157-9ff8-46ad-c15a-bb1a1fbb6995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'uci_id': 193, 'name': 'Cardiotocography', 'repository_url': 'https://archive.ics.uci.edu/dataset/193/cardiotocography', 'data_url': 'https://archive.ics.uci.edu/static/public/193/data.csv', 'abstract': 'The dataset consists of measurements of fetal heart rate (FHR) and uterine contraction (UC) features on cardiotocograms classified by expert obstetricians.', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 2126, 'num_features': 21, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['CLASS', 'NSP'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2000, 'last_updated': 'Fri Mar 15 2024', 'dataset_doi': '10.24432/C51S4N', 'creators': ['D. Campos', 'J. Bernardes'], 'intro_paper': None, 'additional_info': {'summary': '2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'LB - FHR baseline (beats per minute)\\r\\nAC - # of accelerations per second\\r\\nFM - # of fetal movements per second\\r\\nUC - # of uterine contractions per second\\r\\nDL - # of light decelerations per second\\r\\nDS - # of severe decelerations per second\\r\\nDP - # of prolongued decelerations per second\\r\\nASTV - percentage of time with abnormal short term variability\\r\\nMSTV - mean value of short term variability\\r\\nALTV - percentage of time with abnormal long term variability\\r\\nMLTV - mean value of long term variability\\r\\nWidth - width of FHR histogram\\r\\nMin - minimum of FHR histogram\\r\\nMax - Maximum of FHR histogram\\r\\nNmax - # of histogram peaks\\r\\nNzeros - # of histogram zeros\\r\\nMode - histogram mode\\r\\nMean - histogram mean\\r\\nMedian - histogram median\\r\\nVariance - histogram variance\\r\\nTendency - histogram tendency\\r\\nCLASS - FHR pattern class code (1 to 10) \\r\\nNSP - fetal state class code (N=normal; S=suspect; P=pathologic)', 'citation': None}}\n",
            "        name     role        type demographic description units missing_values\n",
            "0         LB  Feature     Integer        None        None  None             no\n",
            "1         AC  Feature  Continuous        None        None  None             no\n",
            "2         FM  Feature  Continuous        None        None  None             no\n",
            "3         UC  Feature  Continuous        None        None  None             no\n",
            "4         DL  Feature  Continuous        None        None  None             no\n",
            "5         DS  Feature  Continuous        None        None  None             no\n",
            "6         DP  Feature  Continuous        None        None  None             no\n",
            "7       ASTV  Feature     Integer        None        None  None             no\n",
            "8       MSTV  Feature  Continuous        None        None  None             no\n",
            "9       ALTV  Feature     Integer        None        None  None             no\n",
            "10      MLTV  Feature  Continuous        None        None  None             no\n",
            "11     Width  Feature     Integer        None        None  None             no\n",
            "12       Min  Feature     Integer        None        None  None             no\n",
            "13       Max  Feature     Integer        None        None  None             no\n",
            "14      Nmax  Feature     Integer        None        None  None             no\n",
            "15    Nzeros  Feature     Integer        None        None  None             no\n",
            "16      Mode  Feature     Integer        None        None  None             no\n",
            "17      Mean  Feature     Integer        None        None  None             no\n",
            "18    Median  Feature     Integer        None        None  None             no\n",
            "19  Variance  Feature     Integer        None        None  None             no\n",
            "20  Tendency  Feature     Integer        None        None  None             no\n",
            "21     CLASS   Target     Integer        None        None  None             no\n",
            "22       NSP   Target     Integer        None        None  None             no\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "cardiotocography = fetch_ucirepo(id=193)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = cardiotocography.data.features\n",
        "y = cardiotocography.data.targets\n",
        "\n",
        "# metadata\n",
        "print(cardiotocography.metadata)\n",
        "\n",
        "# variable information\n",
        "print(cardiotocography.variables)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "I6--6V_U0C08",
        "outputId": "2901b325-7c7d-4e09-a245-4b8782258b2e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3ce10eda-ac12-4eb5-a255-50362ef174f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LB</th>\n",
              "      <th>AC</th>\n",
              "      <th>FM</th>\n",
              "      <th>UC</th>\n",
              "      <th>DL</th>\n",
              "      <th>DS</th>\n",
              "      <th>DP</th>\n",
              "      <th>ASTV</th>\n",
              "      <th>MSTV</th>\n",
              "      <th>ALTV</th>\n",
              "      <th>...</th>\n",
              "      <th>Width</th>\n",
              "      <th>Min</th>\n",
              "      <th>Max</th>\n",
              "      <th>Nmax</th>\n",
              "      <th>Nzeros</th>\n",
              "      <th>Mode</th>\n",
              "      <th>Mean</th>\n",
              "      <th>Median</th>\n",
              "      <th>Variance</th>\n",
              "      <th>Tendency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73</td>\n",
              "      <td>0.5</td>\n",
              "      <td>43</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>62</td>\n",
              "      <td>126</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>137</td>\n",
              "      <td>121</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>132</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>130</td>\n",
              "      <td>68</td>\n",
              "      <td>198</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>136</td>\n",
              "      <td>140</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>130</td>\n",
              "      <td>68</td>\n",
              "      <td>198</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>135</td>\n",
              "      <td>138</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>134</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>117</td>\n",
              "      <td>53</td>\n",
              "      <td>170</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>134</td>\n",
              "      <td>137</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>132</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>117</td>\n",
              "      <td>53</td>\n",
              "      <td>170</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>136</td>\n",
              "      <td>138</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ce10eda-ac12-4eb5-a255-50362ef174f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ce10eda-ac12-4eb5-a255-50362ef174f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ce10eda-ac12-4eb5-a255-50362ef174f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-735a4a7a-e4d8-48a1-8dfc-3aa3781c411e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-735a4a7a-e4d8-48a1-8dfc-3aa3781c411e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-735a4a7a-e4d8-48a1-8dfc-3aa3781c411e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    LB     AC   FM     UC     DL   DS   DP  ASTV  MSTV  ALTV  ...  Width  Min  \\\n",
              "0  120  0.000  0.0  0.000  0.000  0.0  0.0    73   0.5    43  ...     64   62   \n",
              "1  132  0.006  0.0  0.006  0.003  0.0  0.0    17   2.1     0  ...    130   68   \n",
              "2  133  0.003  0.0  0.008  0.003  0.0  0.0    16   2.1     0  ...    130   68   \n",
              "3  134  0.003  0.0  0.008  0.003  0.0  0.0    16   2.4     0  ...    117   53   \n",
              "4  132  0.007  0.0  0.008  0.000  0.0  0.0    16   2.4     0  ...    117   53   \n",
              "\n",
              "   Max  Nmax  Nzeros  Mode  Mean  Median  Variance  Tendency  \n",
              "0  126     2       0   120   137     121        73         1  \n",
              "1  198     6       1   141   136     140        12         0  \n",
              "2  198     5       1   141   135     138        13         0  \n",
              "3  170    11       0   137   134     137        13         1  \n",
              "4  170     9       0   137   136     138        11         1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AGC0vYiA0OXW",
        "outputId": "5f6e3ca3-292a-45d8-cad2-78b394694fbd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"y\",\n  \"rows\": 2126,\n  \"fields\": [\n    {\n      \"column\": \"CLASS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5,\n          6,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NSP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "y"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-217c8a60-b592-4f34-b951-21cf2e8ad4ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLASS</th>\n",
              "      <th>NSP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-217c8a60-b592-4f34-b951-21cf2e8ad4ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-217c8a60-b592-4f34-b951-21cf2e8ad4ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-217c8a60-b592-4f34-b951-21cf2e8ad4ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4de4f9ea-52e9-45da-856c-cc3a57667bb9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4de4f9ea-52e9-45da-856c-cc3a57667bb9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4de4f9ea-52e9-45da-856c-cc3a57667bb9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   CLASS  NSP\n",
              "0      9    2\n",
              "1      6    1\n",
              "2      6    1\n",
              "3      6    1\n",
              "4      2    1"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4oUsjeJ16Xw"
      },
      "source": [
        "## Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC53HbTX18uk"
      },
      "outputs": [],
      "source": [
        "y = y[\"NSP\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFQSFqQc3GFe"
      },
      "source": [
        "There is some data imbalance here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFndd_-M190R",
        "outputId": "6b3dd57b-c083-4955-aa7e-4680668c4ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of normal:  1655\n",
            "Number of suspect:  295\n",
            "Number of pathological:  176\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of normal: \", (y == 1).sum())\n",
        "print(\"Number of suspect: \", (y == 2).sum())\n",
        "print(\"Number of pathological: \", (y == 3).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SfzyuyS3nly"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF0Fq3YT3PX8",
        "outputId": "990c99c8-a417-4a65-e406-dc789b27923c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The features: \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',\n",
              "       'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',\n",
              "       'Median', 'Variance', 'Tendency'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"The features: \")\n",
        "X.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flokEwHT4igM"
      },
      "source": [
        "Below we can see that the features 'LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV', 'MLTV' don't seem to show high correlation which is a good sign. The only highly correlated features are 'mode', 'mean' and 'median' which is expected. Highly correlated features can cause unstable training for regression models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN-QjXYV4PSf"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "matrix = X.corr()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(matrix, annot=False, cmap=\"coolwarm\", linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlDD1kO5_u9a"
      },
      "source": [
        "I am using L1 regularization for feature selection with multinomial logistic regression. I am no doctor but ChatGPT is and according to him the coefficients below makes sense.\n",
        "\n",
        "However, I suspect that the \"suspect\" class may be difficult to predict for a classifier because it lies between the normal and pathological categories and shares features with both.... I think one way around this may be to train a binary classifier that predicts \"normal\" or \"pathological\", and classify as suspect if the predicted probability is close to the threshold probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAy_3Rtv4Vj8",
        "outputId": "12881894-0bdc-4239-9740-3a7922fb436e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# features = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV', 'MLTV']\n",
        "# X_to_be_scaled = X[features]\n",
        "X_to_be_scaled = X\n",
        "\n",
        "# normalize\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_to_be_scaled)\n",
        "\n",
        "# logistic regression with L1 penalty\n",
        "log_reg_l1 = LogisticRegression(\n",
        "    penalty=\"l1\",\n",
        "    solver=\"saga\",\n",
        "    multi_class=\"multinomial\",\n",
        "    C=0.1, # smaller C means stronger regularization\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "log_reg_l1.fit(X_scaled, y)\n",
        "\n",
        "# feature importance\n",
        "coef = log_reg_l1.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muYH5kbNAoDL",
        "outputId": "a7e58d26-d223-43ce-c9c3-0f01d0310418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coef for normal model: \n",
            " [ 0.          2.19435103 -0.21961309  0.58176449  0.          0.\n",
            " -1.01593461 -1.07726337  0.02787448 -0.39027387  0.          0.\n",
            " -0.04341775 -0.19201244  0.          0.          0.          0.\n",
            "  0.         -0.44504368  0.        ]\n",
            "\n",
            "coef for normal suspect: \n",
            " [ 0.          0.          0.          0.         -0.1840667   0.\n",
            "  0.          0.         -0.09760563  0.          0.          0.\n",
            "  0.02591755  0.          0.21369675  0.          0.          1.17065434\n",
            "  0.          0.          0.        ]\n",
            "\n",
            "coef for normal pathological: \n",
            " [ 0.18140649  0.          0.03600714  0.          0.0988348   0.05994576\n",
            "  0.21378486  0.69812008  0.          0.5235395   0.          0.\n",
            "  0.          0.         -0.16950175  0.         -0.62663459  0.\n",
            " -0.08829534  0.45970532  0.        ]\n"
          ]
        }
      ],
      "source": [
        "print(\"coef for normal model: \\n\", coef[0])\n",
        "print()\n",
        "print(\"coef for normal suspect: \\n\", coef[1])\n",
        "print()\n",
        "print(\"coef for normal pathological: \\n\", coef[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybMBGk55G0nr"
      },
      "source": [
        "## Experiments\n",
        "\n",
        "These are some quick experiments with simple models so I have not taken any proper measures to handle the data imbalance or prevent overfitting on the training data with a validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MLsOsxuCLdV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X = X[features]\n",
        "\n",
        "# we should ensure that the train-test split split is stratified\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "y_train -= 1\n",
        "y_test -= 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lslWsXXLYzBv"
      },
      "source": [
        "### Linear models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfNfG_IxIVaA"
      },
      "source": [
        "As expected the f1-score for the \"suspect\" class is a little weaker for logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAXZtEsOHA1j",
        "outputId": "284789c3-6f18-4ec3-cef2-7160ebe4f297"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.95       332\n",
            "           1       0.62      0.68      0.65        59\n",
            "           2       0.89      0.69      0.77        35\n",
            "\n",
            "    accuracy                           0.89       426\n",
            "   macro avg       0.82      0.77      0.79       426\n",
            "weighted avg       0.89      0.89      0.89       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "log_reg_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"logreg\", LogisticRegression(\n",
        "        penalty=\"l1\", solver=\"saga\", multi_class=\"multinomial\", max_iter=5000\n",
        "    ))\n",
        "])\n",
        "\n",
        "log_reg_pipeline.fit(X_train, y_train)\n",
        "y_pred_lr = log_reg_pipeline.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXl4fubaY11M"
      },
      "source": [
        "### Tree models and ensembles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I91Jv4BRLIBG"
      },
      "source": [
        "As expected with most classical ML problems with tabular data, tree based models perform a little better than logistic/ linear regression because they are non-linear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lW04QpRHqsi",
        "outputId": "51e08be4-7599-41f1-ff75-b0c70bb03062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.95       332\n",
            "           1       0.73      0.64      0.68        59\n",
            "           2       0.81      0.83      0.82        35\n",
            "\n",
            "    accuracy                           0.90       426\n",
            "   macro avg       0.82      0.81      0.82       426\n",
            "weighted avg       0.90      0.90      0.90       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tree = DecisionTreeClassifier(\n",
        "    criterion=\"gini\",\n",
        "    max_depth=None,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred_tree = tree.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred_tree))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFbzsW4GiDUG"
      },
      "source": [
        "Since the data is not noisy, boosting methods likely outperform bagging methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiC_a_DSdr5T",
        "outputId": "cff48bd7-27cb-4e30-e5ab-e63f7eeced70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1216\n",
            "[LightGBM] [Info] Number of data points in the train set: 1700, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       332\n",
            "           1       0.85      0.80      0.82        59\n",
            "           2       0.89      0.94      0.92        35\n",
            "\n",
            "    accuracy                           0.95       426\n",
            "   macro avg       0.91      0.91      0.90       426\n",
            "weighted avg       0.95      0.95      0.95       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "lgbm = LGBMClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    random_state=43,\n",
        "    class_weight=\"balanced\"   # helps with imbalance\n",
        ")\n",
        "\n",
        "lgbm.fit(X_train, y_train)\n",
        "y_pred = lgbm.predict(X_test)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqPecGXVeNnp",
        "outputId": "eaa10a60-1b88-44c7-93bd-d49709c7d277"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [13:32:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       332\n",
            "           1       0.86      0.71      0.78        59\n",
            "           2       0.91      0.91      0.91        35\n",
            "\n",
            "    accuracy                           0.94       426\n",
            "   macro avg       0.91      0.87      0.89       426\n",
            "weighted avg       0.93      0.94      0.93       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Base estimator: XGBoost\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=200,        # boosting rounds per base model\n",
        "    learning_rate=0.05,\n",
        "    max_depth=20,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=43,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"logloss\",\n",
        "    scale_pos_weight=1\n",
        ")\n",
        "\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred = xgb.predict(X_test)\n",
        "\n",
        "# Report\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPI-Hm09Yo7J"
      },
      "source": [
        "SelfPacedEnsembleClassifier is specially designed to handle class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQmK4G_DJogu",
        "outputId": "f2ceeb80-3bcf-4c02-faa2-4b77276ac5e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97       332\n",
            "           1       0.82      0.78      0.80        59\n",
            "           2       0.89      0.94      0.92        35\n",
            "\n",
            "    accuracy                           0.94       426\n",
            "   macro avg       0.89      0.90      0.89       426\n",
            "weighted avg       0.94      0.94      0.94       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from imbens.ensemble import SelfPacedEnsembleClassifier\n",
        "\n",
        "SPE = SelfPacedEnsembleClassifier(random_state=41)\n",
        "SPE.fit(X_train, y_train)\n",
        "\n",
        "y_pred = SPE.predict(X_test)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dkviVtJPKJw",
        "outputId": "255e73ff-2d9c-4d96-91a5-490c9f58e20d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.82      0.89       332\n",
            "           1       0.46      0.85      0.60        59\n",
            "           2       0.88      0.83      0.85        35\n",
            "\n",
            "    accuracy                           0.83       426\n",
            "   macro avg       0.77      0.83      0.78       426\n",
            "weighted avg       0.88      0.83      0.84       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from imbens.ensemble import SMOTEBoostClassifier\n",
        "\n",
        "SB = SMOTEBoostClassifier(random_state=41)\n",
        "SB.fit(X_train, y_train)\n",
        "\n",
        "y_pred = SB.predict(X_test)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiU7RmA3m9YX"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpBvCuONm_GM",
        "outputId": "594c5059-f697-456d-9c39-10b1930cde24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "KNN Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       332\n",
            "           1       0.61      0.47      0.53        59\n",
            "           2       0.88      0.66      0.75        35\n",
            "\n",
            "    accuracy                           0.87       426\n",
            "   macro avg       0.80      0.70      0.74       426\n",
            "weighted avg       0.86      0.87      0.86       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "knn_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"knn\", KNeighborsClassifier(\n",
        "        n_neighbors=5,\n",
        "        metric=\"minkowski\",\n",
        "        weights=\"uniform\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "knn_pipeline.fit(X_train, y_train)\n",
        "y_pred_knn = knn_pipeline.predict(X_test)\n",
        "\n",
        "print(\"\\nKNN Classification Report:\\n\", classification_report(y_test, y_pred_knn))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBLiS6O2Y5UD"
      },
      "source": [
        "### Neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0m2YEDfqLN1"
      },
      "source": [
        "TabNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65qX9p1PqK_b",
        "outputId": "924063d2-46a3-44fa-838b-33f134bf42a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 0.71267 | val_0_accuracy: 0.7277  |  0:00:01s\n",
            "epoch 1  | loss: 0.47532 | val_0_accuracy: 0.73944 |  0:00:03s\n",
            "epoch 2  | loss: 0.4108  | val_0_accuracy: 0.723   |  0:00:05s\n",
            "epoch 3  | loss: 0.38797 | val_0_accuracy: 0.79343 |  0:00:06s\n",
            "epoch 4  | loss: 0.33988 | val_0_accuracy: 0.78638 |  0:00:09s\n",
            "epoch 5  | loss: 0.32473 | val_0_accuracy: 0.80516 |  0:00:11s\n",
            "epoch 6  | loss: 0.30798 | val_0_accuracy: 0.79577 |  0:00:12s\n",
            "epoch 7  | loss: 0.32647 | val_0_accuracy: 0.8216  |  0:00:14s\n",
            "epoch 8  | loss: 0.30647 | val_0_accuracy: 0.80516 |  0:00:16s\n",
            "epoch 9  | loss: 0.31835 | val_0_accuracy: 0.80047 |  0:00:17s\n",
            "epoch 10 | loss: 0.2919  | val_0_accuracy: 0.79343 |  0:00:19s\n",
            "epoch 11 | loss: 0.29214 | val_0_accuracy: 0.80751 |  0:00:21s\n",
            "epoch 12 | loss: 0.32868 | val_0_accuracy: 0.81221 |  0:00:23s\n",
            "epoch 13 | loss: 0.29238 | val_0_accuracy: 0.82394 |  0:00:25s\n",
            "epoch 14 | loss: 0.30241 | val_0_accuracy: 0.84272 |  0:00:26s\n",
            "epoch 15 | loss: 0.28692 | val_0_accuracy: 0.83099 |  0:00:28s\n",
            "epoch 16 | loss: 0.28508 | val_0_accuracy: 0.8662  |  0:00:30s\n",
            "epoch 17 | loss: 0.2761  | val_0_accuracy: 0.87089 |  0:00:31s\n",
            "epoch 18 | loss: 0.30665 | val_0_accuracy: 0.84742 |  0:00:33s\n",
            "epoch 19 | loss: 0.30308 | val_0_accuracy: 0.87089 |  0:00:35s\n",
            "epoch 20 | loss: 0.30603 | val_0_accuracy: 0.86385 |  0:00:39s\n",
            "epoch 21 | loss: 0.29096 | val_0_accuracy: 0.86854 |  0:00:40s\n",
            "epoch 22 | loss: 0.27479 | val_0_accuracy: 0.84977 |  0:00:42s\n",
            "epoch 23 | loss: 0.30134 | val_0_accuracy: 0.85446 |  0:00:44s\n",
            "epoch 24 | loss: 0.27064 | val_0_accuracy: 0.87793 |  0:00:45s\n",
            "epoch 25 | loss: 0.26844 | val_0_accuracy: 0.85681 |  0:00:47s\n",
            "epoch 26 | loss: 0.27172 | val_0_accuracy: 0.87089 |  0:00:49s\n",
            "epoch 27 | loss: 0.27228 | val_0_accuracy: 0.86854 |  0:00:51s\n",
            "epoch 28 | loss: 0.27596 | val_0_accuracy: 0.87324 |  0:00:54s\n",
            "epoch 29 | loss: 0.26158 | val_0_accuracy: 0.87559 |  0:00:56s\n",
            "epoch 30 | loss: 0.28056 | val_0_accuracy: 0.85681 |  0:00:57s\n",
            "epoch 31 | loss: 0.26285 | val_0_accuracy: 0.84977 |  0:00:59s\n",
            "epoch 32 | loss: 0.28588 | val_0_accuracy: 0.8615  |  0:01:03s\n",
            "epoch 33 | loss: 0.25556 | val_0_accuracy: 0.87559 |  0:01:09s\n",
            "epoch 34 | loss: 0.29186 | val_0_accuracy: 0.87089 |  0:01:12s\n",
            "epoch 35 | loss: 0.26174 | val_0_accuracy: 0.86854 |  0:01:15s\n",
            "epoch 36 | loss: 0.26234 | val_0_accuracy: 0.87793 |  0:01:20s\n",
            "epoch 37 | loss: 0.26157 | val_0_accuracy: 0.86385 |  0:01:25s\n",
            "epoch 38 | loss: 0.2493  | val_0_accuracy: 0.88263 |  0:01:26s\n",
            "epoch 39 | loss: 0.26339 | val_0_accuracy: 0.88732 |  0:01:28s\n",
            "epoch 40 | loss: 0.25809 | val_0_accuracy: 0.87793 |  0:01:32s\n",
            "epoch 41 | loss: 0.25251 | val_0_accuracy: 0.8662  |  0:01:37s\n",
            "epoch 42 | loss: 0.26313 | val_0_accuracy: 0.87324 |  0:01:39s\n",
            "epoch 43 | loss: 0.26207 | val_0_accuracy: 0.8662  |  0:01:40s\n",
            "epoch 44 | loss: 0.24526 | val_0_accuracy: 0.87793 |  0:01:42s\n",
            "epoch 45 | loss: 0.26311 | val_0_accuracy: 0.8615  |  0:01:43s\n",
            "epoch 46 | loss: 0.24366 | val_0_accuracy: 0.8662  |  0:01:45s\n",
            "epoch 47 | loss: 0.24862 | val_0_accuracy: 0.87324 |  0:01:47s\n",
            "epoch 48 | loss: 0.2671  | val_0_accuracy: 0.87559 |  0:01:49s\n",
            "epoch 49 | loss: 0.2728  | val_0_accuracy: 0.88028 |  0:01:51s\n",
            "epoch 50 | loss: 0.25246 | val_0_accuracy: 0.87089 |  0:01:53s\n",
            "epoch 51 | loss: 0.25258 | val_0_accuracy: 0.88732 |  0:01:54s\n",
            "epoch 52 | loss: 0.23605 | val_0_accuracy: 0.88028 |  0:01:56s\n",
            "epoch 53 | loss: 0.27045 | val_0_accuracy: 0.86385 |  0:01:58s\n",
            "epoch 54 | loss: 0.26072 | val_0_accuracy: 0.87089 |  0:01:59s\n",
            "epoch 55 | loss: 0.25312 | val_0_accuracy: 0.87559 |  0:02:02s\n",
            "epoch 56 | loss: 0.23307 | val_0_accuracy: 0.8662  |  0:02:04s\n",
            "epoch 57 | loss: 0.23601 | val_0_accuracy: 0.87089 |  0:02:06s\n",
            "epoch 58 | loss: 0.22832 | val_0_accuracy: 0.8615  |  0:02:07s\n",
            "epoch 59 | loss: 0.22789 | val_0_accuracy: 0.88263 |  0:02:09s\n",
            "\n",
            "Early stopping occurred at epoch 59 with best_epoch = 39 and best_val_0_accuracy = 0.88732\n",
            "\n",
            "TabNet Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95       332\n",
            "           1       0.60      0.75      0.67        59\n",
            "           2       0.91      0.57      0.70        35\n",
            "\n",
            "    accuracy                           0.89       426\n",
            "   macro avg       0.82      0.75      0.77       426\n",
            "weighted avg       0.90      0.89      0.89       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert data\n",
        "X_train_np = X_train.values if hasattr(X_train, \"values\") else X_train\n",
        "y_train_np = y_train.values if hasattr(y_train, \"values\") else y_train\n",
        "X_test_np = X_test.values if hasattr(X_test, \"values\") else X_test\n",
        "y_test_np = y_test.values if hasattr(y_test, \"values\") else y_test\n",
        "\n",
        "# Initialize TabNet on GPU\n",
        "tabnet = TabNetClassifier(\n",
        "    n_d=8, n_a=8, n_steps=3,\n",
        "    gamma=1.3, n_independent=2, n_shared=2,\n",
        "    momentum=0.3,\n",
        "    seed=42,\n",
        "    verbose=1,\n",
        "    device_name=\"cuda\"\n",
        ")\n",
        "\n",
        "# Train\n",
        "tabnet.fit(\n",
        "    X_train_np, y_train_np,\n",
        "    eval_set=[(X_test_np, y_test_np)],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=200,\n",
        "    patience=20,\n",
        "    batch_size=32,\n",
        "    virtual_batch_size=32,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Predict\n",
        "y_pred = tabnet.predict(X_test_np)\n",
        "\n",
        "# Report\n",
        "print(\"\\nTabNet Classification Report:\\n\", classification_report(y_test_np, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjjMCamswaHH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# focal loss\n",
        "class BinaryFocalLoss(torch.nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2):\n",
        "        super(BinaryFocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # Using the functional version of BCEWithLogitsLoss so that we can get the unreduced\n",
        "        # losses (for the Hadamard product)\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets.unsqueeze(1), reduction=\"none\")\n",
        "\n",
        "        # Apply sigmoid to get probabilities\n",
        "        probs = torch.sigmoid(inputs)\n",
        "        # For targets=1, we use p, for targets=0, we use 1-p\n",
        "        pt = probs * targets + (1 - probs) * (1 - targets)\n",
        "\n",
        "        # Focusing term\n",
        "        focal_weight = (1 - pt).pow(self.gamma)\n",
        "\n",
        "        # Apply alpha weighting\n",
        "        if self.alpha is not None:\n",
        "            # Alpha for positive samples, 1-alpha for negative samples\n",
        "            alpha_weight = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
        "            focal_weight = focal_weight * alpha_weight\n",
        "\n",
        "        focal_loss = focal_weight * bce_loss\n",
        "\n",
        "        return torch.mean(focal_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbCIPJRPxvLe"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha  # tensor of shape [num_classes] or None\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # inputs: [batch_size, num_classes]\n",
        "        # targets: [batch_size] (class indices)\n",
        "\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)  # equivalent to softmax prob of the true class\n",
        "\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            at = self.alpha.gather(0, targets)\n",
        "            focal_loss = at * focal_loss\n",
        "\n",
        "        return focal_loss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBAroV1_0QqO"
      },
      "source": [
        "Testing with 3 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DrC1RGo6YEc2",
        "outputId": "d6ceaf94-46c2-494e-f328-d017273212af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/60], Loss: 0.0643\n",
            "Validation Loss: 0.0622\n",
            "   Saving model...\n",
            "Epoch [2/60], Loss: 0.0571\n",
            "Validation Loss: 0.0565\n",
            "   Saving model...\n",
            "Epoch [3/60], Loss: 0.0510\n",
            "Validation Loss: 0.0508\n",
            "   Saving model...\n",
            "Epoch [4/60], Loss: 0.0448\n",
            "Validation Loss: 0.0458\n",
            "   Saving model...\n",
            "Epoch [5/60], Loss: 0.0380\n",
            "Validation Loss: 0.0412\n",
            "   Saving model...\n",
            "Epoch [6/60], Loss: 0.0339\n",
            "Validation Loss: 0.0376\n",
            "   Saving model...\n",
            "Epoch [7/60], Loss: 0.0303\n",
            "Validation Loss: 0.0350\n",
            "   Saving model...\n",
            "Epoch [8/60], Loss: 0.0282\n",
            "Validation Loss: 0.0325\n",
            "   Saving model...\n",
            "Epoch [9/60], Loss: 0.0248\n",
            "Validation Loss: 0.0305\n",
            "   Saving model...\n",
            "Epoch [10/60], Loss: 0.0239\n",
            "Validation Loss: 0.0287\n",
            "   Saving model...\n",
            "Epoch [11/60], Loss: 0.0226\n",
            "Validation Loss: 0.0278\n",
            "   Saving model...\n",
            "Epoch [12/60], Loss: 0.0212\n",
            "Validation Loss: 0.0258\n",
            "   Saving model...\n",
            "Epoch [13/60], Loss: 0.0199\n",
            "Validation Loss: 0.0251\n",
            "   Saving model...\n",
            "Epoch [14/60], Loss: 0.0188\n",
            "Validation Loss: 0.0242\n",
            "   Saving model...\n",
            "Epoch [15/60], Loss: 0.0189\n",
            "Validation Loss: 0.0236\n",
            "   Saving model...\n",
            "Epoch [16/60], Loss: 0.0172\n",
            "Validation Loss: 0.0230\n",
            "   Saving model...\n",
            "Epoch [17/60], Loss: 0.0171\n",
            "Validation Loss: 0.0226\n",
            "   Saving model...\n",
            "Epoch [18/60], Loss: 0.0169\n",
            "Validation Loss: 0.0222\n",
            "   Saving model...\n",
            "Epoch [19/60], Loss: 0.0157\n",
            "Validation Loss: 0.0220\n",
            "   Saving model...\n",
            "Epoch [20/60], Loss: 0.0156\n",
            "Validation Loss: 0.0216\n",
            "   Saving model...\n",
            "Epoch [21/60], Loss: 0.0149\n",
            "Validation Loss: 0.0218\n",
            "Epoch [22/60], Loss: 0.0145\n",
            "Validation Loss: 0.0215\n",
            "   Saving model...\n",
            "Epoch [23/60], Loss: 0.0153\n",
            "Validation Loss: 0.0214\n",
            "   Saving model...\n",
            "Epoch [24/60], Loss: 0.0142\n",
            "Validation Loss: 0.0218\n",
            "Epoch [25/60], Loss: 0.0134\n",
            "Validation Loss: 0.0216\n",
            "Epoch [26/60], Loss: 0.0130\n",
            "Validation Loss: 0.0217\n",
            "Epoch [27/60], Loss: 0.0145\n",
            "Validation Loss: 0.0214\n",
            "Epoch [28/60], Loss: 0.0128\n",
            "Validation Loss: 0.0219\n",
            "Epoch [29/60], Loss: 0.0126\n",
            "Validation Loss: 0.0223\n",
            "Epoch [30/60], Loss: 0.0124\n",
            "Validation Loss: 0.0219\n",
            "Epoch [31/60], Loss: 0.0122\n",
            "Validation Loss: 0.0221\n",
            "Epoch [32/60], Loss: 0.0118\n",
            "Validation Loss: 0.0221\n",
            "Epoch [33/60], Loss: 0.0124\n",
            "Validation Loss: 0.0219\n",
            "Epoch [34/60], Loss: 0.0116\n",
            "Validation Loss: 0.0219\n",
            "Epoch [35/60], Loss: 0.0114\n",
            "Validation Loss: 0.0229\n",
            "Epoch [36/60], Loss: 0.0116\n",
            "Validation Loss: 0.0218\n",
            "Epoch [37/60], Loss: 0.0114\n",
            "Validation Loss: 0.0224\n",
            "Epoch [38/60], Loss: 0.0111\n",
            "Validation Loss: 0.0223\n",
            "Epoch [39/60], Loss: 0.0107\n",
            "Validation Loss: 0.0224\n",
            "Epoch [40/60], Loss: 0.0111\n",
            "Validation Loss: 0.0228\n",
            "Epoch [41/60], Loss: 0.0107\n",
            "Validation Loss: 0.0224\n",
            "Epoch [42/60], Loss: 0.0106\n",
            "Validation Loss: 0.0229\n",
            "Epoch [43/60], Loss: 0.0105\n",
            "Validation Loss: 0.0225\n",
            "Epoch [44/60], Loss: 0.0106\n",
            "Validation Loss: 0.0235\n",
            "Epoch [45/60], Loss: 0.0100\n",
            "Validation Loss: 0.0237\n",
            "Epoch [46/60], Loss: 0.0106\n",
            "Validation Loss: 0.0222\n",
            "Epoch [47/60], Loss: 0.0100\n",
            "Validation Loss: 0.0235\n",
            "Epoch [48/60], Loss: 0.0104\n",
            "Validation Loss: 0.0227\n",
            "Epoch [49/60], Loss: 0.0102\n",
            "Validation Loss: 0.0235\n",
            "Epoch [50/60], Loss: 0.0099\n",
            "Validation Loss: 0.0232\n",
            "Epoch [51/60], Loss: 0.0096\n",
            "Validation Loss: 0.0237\n",
            "Epoch [52/60], Loss: 0.0097\n",
            "Validation Loss: 0.0227\n",
            "Epoch [53/60], Loss: 0.0093\n",
            "Validation Loss: 0.0242\n",
            "Epoch [54/60], Loss: 0.0095\n",
            "Validation Loss: 0.0228\n",
            "Epoch [55/60], Loss: 0.0101\n",
            "Validation Loss: 0.0239\n",
            "Epoch [56/60], Loss: 0.0094\n",
            "Validation Loss: 0.0241\n",
            "Epoch [57/60], Loss: 0.0094\n",
            "Validation Loss: 0.0234\n",
            "Epoch [58/60], Loss: 0.0089\n",
            "Validation Loss: 0.0244\n",
            "Epoch [59/60], Loss: 0.0097\n",
            "Validation Loss: 0.0234\n",
            "Epoch [60/60], Loss: 0.0090\n",
            "Validation Loss: 0.0227\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.84      0.91       332\n",
            "           1       0.51      0.85      0.63        59\n",
            "           2       0.57      0.69      0.62        35\n",
            "\n",
            "    accuracy                           0.83       426\n",
            "   macro avg       0.69      0.79      0.72       426\n",
            "weighted avg       0.88      0.83      0.85       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_nn = y.map({1: 0, 2: 1, 3: 2})\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y_nn,\n",
        "    test_size=0.2,\n",
        "    stratify=y_nn,\n",
        "    random_state=40\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.2,\n",
        "    stratify=y_temp,\n",
        "    random_state=40\n",
        ")\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train.values, dtype=torch.long)  # labels as integers\n",
        "\n",
        "X_val_t = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
        "y_val_t = torch.tensor(y_val.values, dtype=torch.long)\n",
        "\n",
        "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# using class weights\n",
        "class_counts = torch.bincount(y_train_t)\n",
        "class_weights = 1.0 / class_counts\n",
        "class_weights = class_weights / class_weights.sum()\n",
        "\n",
        "# the model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(hidden_dim, hidden_dim),\n",
        "            # nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "input_dim = X_train.shape[1]   # number of features\n",
        "hidden_dim = 12\n",
        "output_dim = len(set(y_train)) # number of classes\n",
        "\n",
        "model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# loss and optimizer\n",
        "# criterion = nn.CrossEntropyLoss(\n",
        "#     weight=class_weights\n",
        "# )\n",
        "criterion = FocalLoss(alpha=class_weights, gamma=2)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "# training loop\n",
        "epochs = 60\n",
        "min_val_loss = float('inf')\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # validation\n",
        "    val_output = model(X_val_t) # if the val set were bigger i would use a dataloader for this\n",
        "    val_loss = criterion(val_output, y_val_t)\n",
        "    print(f\"Validation Loss: {val_loss.item():.4f}\")\n",
        "    if val_loss.item() < min_val_loss:\n",
        "        min_val_loss = val_loss.item()\n",
        "        print(\"   Saving model...\")\n",
        "        # torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "# evaluation\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        outputs = model(X_batch)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.numpy())\n",
        "        all_labels.extend(y_batch.numpy())\n",
        "\n",
        "print(classification_report(all_labels, all_preds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnrpOw1p2WLV"
      },
      "source": [
        "Simplifying to 2 classes, the performance looks much better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8WI8hLHobN07",
        "outputId": "e65d1ca8-f441-421a-f769-7a21c592afa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/30], Loss: 0.6517\n",
            "Validation Loss: 0.5960\n",
            "   Saving model...\n",
            "Epoch [2/30], Loss: 0.5331\n",
            "Validation Loss: 0.4798\n",
            "   Saving model...\n",
            "Epoch [3/30], Loss: 0.4240\n",
            "Validation Loss: 0.3848\n",
            "   Saving model...\n",
            "Epoch [4/30], Loss: 0.3406\n",
            "Validation Loss: 0.3223\n",
            "   Saving model...\n",
            "Epoch [5/30], Loss: 0.2882\n",
            "Validation Loss: 0.2824\n",
            "   Saving model...\n",
            "Epoch [6/30], Loss: 0.2564\n",
            "Validation Loss: 0.2553\n",
            "   Saving model...\n",
            "Epoch [7/30], Loss: 0.2347\n",
            "Validation Loss: 0.2371\n",
            "   Saving model...\n",
            "Epoch [8/30], Loss: 0.2110\n",
            "Validation Loss: 0.2230\n",
            "   Saving model...\n",
            "Epoch [9/30], Loss: 0.1981\n",
            "Validation Loss: 0.2135\n",
            "   Saving model...\n",
            "Epoch [10/30], Loss: 0.1902\n",
            "Validation Loss: 0.2079\n",
            "   Saving model...\n",
            "Epoch [11/30], Loss: 0.1839\n",
            "Validation Loss: 0.2036\n",
            "   Saving model...\n",
            "Epoch [12/30], Loss: 0.1816\n",
            "Validation Loss: 0.2009\n",
            "   Saving model...\n",
            "Epoch [13/30], Loss: 0.1832\n",
            "Validation Loss: 0.1984\n",
            "   Saving model...\n",
            "Epoch [14/30], Loss: 0.1717\n",
            "Validation Loss: 0.1976\n",
            "   Saving model...\n",
            "Epoch [15/30], Loss: 0.1741\n",
            "Validation Loss: 0.1957\n",
            "   Saving model...\n",
            "Epoch [16/30], Loss: 0.1704\n",
            "Validation Loss: 0.1948\n",
            "   Saving model...\n",
            "Epoch [17/30], Loss: 0.1659\n",
            "Validation Loss: 0.1936\n",
            "   Saving model...\n",
            "Epoch [18/30], Loss: 0.1709\n",
            "Validation Loss: 0.1924\n",
            "   Saving model...\n",
            "Epoch [19/30], Loss: 0.1696\n",
            "Validation Loss: 0.1916\n",
            "   Saving model...\n",
            "Epoch [20/30], Loss: 0.1626\n",
            "Validation Loss: 0.1920\n",
            "Epoch [21/30], Loss: 0.1637\n",
            "Validation Loss: 0.1908\n",
            "   Saving model...\n",
            "Epoch [22/30], Loss: 0.1596\n",
            "Validation Loss: 0.1904\n",
            "   Saving model...\n",
            "Epoch [23/30], Loss: 0.1618\n",
            "Validation Loss: 0.1905\n",
            "Epoch [24/30], Loss: 0.1618\n",
            "Validation Loss: 0.1890\n",
            "   Saving model...\n",
            "Epoch [25/30], Loss: 0.1542\n",
            "Validation Loss: 0.1898\n",
            "Epoch [26/30], Loss: 0.1592\n",
            "Validation Loss: 0.1896\n",
            "Epoch [27/30], Loss: 0.1574\n",
            "Validation Loss: 0.1888\n",
            "   Saving model...\n",
            "Epoch [28/30], Loss: 0.1547\n",
            "Validation Loss: 0.1886\n",
            "   Saving model...\n",
            "Epoch [29/30], Loss: 0.1549\n",
            "Validation Loss: 0.1901\n",
            "Epoch [30/30], Loss: 0.1498\n",
            "Validation Loss: 0.1892\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# y_nn = y[(y == 1) | (y == 3)].map({1: 0, 3: 1})\n",
        "# X_nn = X[(y == 1) | (y == 3)]\n",
        "\n",
        "y_nn = y.map({1: 0, 2: 0.5, 3: 1})\n",
        "X_nn = X\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_nn, y_nn,\n",
        "    test_size=0.2,\n",
        "    stratify=y_nn,\n",
        "    random_state=40\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.2,\n",
        "    stratify=y_temp,\n",
        "    random_state=40\n",
        ")\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train.values, dtype=torch.float32)  # labels as float because we have 0.5 now\n",
        "\n",
        "X_val_t = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
        "y_val_t = torch.tensor(y_val.values, dtype=torch.float32)\n",
        "\n",
        "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# using class weights\n",
        "# temp_y = torch.tensor(y_train[(y_train == 0) | (y_train == 1)].values, dtype=torch.long)\n",
        "# class_counts = torch.bincount(temp_y)\n",
        "# class_weights = 1.0 / class_counts\n",
        "# class_weights = class_weights / class_weights.sum()\n",
        "\n",
        "# the model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(hidden_dim, hidden_dim),\n",
        "            # nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "input_dim = X_train.shape[1]   # number of features\n",
        "hidden_dim = 32\n",
        "output_dim = 1 # binary classifier\n",
        "# output_dim = len(set(y_train)) # number of classes\n",
        "\n",
        "model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# loss and optimizer\n",
        "# criterion = nn.CrossEntropyLoss(\n",
        "#     weight=class_weights\n",
        "# )\n",
        "# criterion = BinaryFocalLoss(\n",
        "#     # alpha=class_weights,\n",
        "#     gamma=2\n",
        "# )\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "# training loop\n",
        "epochs = 30\n",
        "min_val_loss = float('inf')\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch.unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    # validation\n",
        "    val_output = model(X_val_t) # if the val set were bigger i would use a dataloader for this\n",
        "    val_loss = criterion(val_output, y_val_t.unsqueeze(1))\n",
        "    print(f\"Validation Loss: {val_loss.item():.4f}\")\n",
        "    if val_loss.item() < min_val_loss:\n",
        "        min_val_loss = val_loss.item()\n",
        "        print(\"   Saving model...\")\n",
        "        # torch.save(model.state_dict(), 'best_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIGsx0gQIN8i",
        "outputId": "b33c001e-094a-4027-8199-347d1f732b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8568\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.92      0.93       344\n",
            "         1.0       0.42      0.57      0.49        44\n",
            "         2.0       0.71      0.66      0.68        38\n",
            "\n",
            "    accuracy                           0.86       426\n",
            "   macro avg       0.70      0.71      0.70       426\n",
            "weighted avg       0.87      0.86      0.86       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "test_output = model(X_test_t)\n",
        "test_probs = torch.sigmoid(test_output).squeeze()\n",
        "\n",
        "# Convert to predicted classes with thresholds\n",
        "test_pred = torch.where(test_probs < 0.33, 0,\n",
        "                      torch.where(test_probs > 0.67, 1, 0.5))\n",
        "\n",
        "# Calculate accuracy\n",
        "correct = (test_pred == y_test_t).sum().item()\n",
        "accuracy = correct / len(y_test_t)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(classification_report(2 * test_pred, 2 * y_test_t))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH7RudaW2dhJ"
      },
      "source": [
        "Trying to classify \"suspect\" below. However I think the model only learn the hard boundary between pathological and normal..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEvX171U2dRh",
        "outputId": "b76a0b98-bcc9-4978-9ce6-e218fc049c03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.]], grad_fn=<SliceBackward0>)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_suspect = y[y == 2]\n",
        "X_suspect = scaler.transform(X[y == 2])\n",
        "\n",
        "X_suspect_t = torch.tensor(X_suspect, dtype=torch.float32)\n",
        "y_suspect_t = torch.tensor(y_suspect.values, dtype=torch.long)\n",
        "\n",
        "model.eval()\n",
        "sussy_output = model(X_suspect_t)\n",
        "sussy_probs = torch.softmax(sussy_output, dim=1)\n",
        "\n",
        "sussy_probs[:10]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXTZt83DHORz"
      },
      "source": [
        "## K-fold cross validation\n",
        "Since XGBoost and LightGBM seem to perform the best, I will do 5-fold cross validation on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3R3-fqklDcU",
        "outputId": "08f670ec-0c18-4031-a7f4-8d85c42d4bd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report (5-fold CV on training set):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.98      0.97      1655\n",
            "           2       0.87      0.73      0.79       295\n",
            "           3       0.95      0.89      0.92       176\n",
            "\n",
            "    accuracy                           0.94      2126\n",
            "   macro avg       0.92      0.87      0.89      2126\n",
            "weighted avg       0.94      0.94      0.94      2126\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "rf = Pipeline([\n",
        "      (\"impute\", SimpleImputer(strategy=\"median\")),\n",
        "      (\"clf\", RandomForestClassifier(\n",
        "          n_estimators=300, class_weight=\"balanced_subsample\",\n",
        "          random_state=43, n_jobs=-1\n",
        "      ))\n",
        "])\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=69)\n",
        "\n",
        "y_pred = cross_val_predict(rf, X, y, cv=kf)\n",
        "\n",
        "print(\"\\nClassification Report (5-fold CV on training set):\\n\")\n",
        "print(classification_report(y, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSp_fe320pSD",
        "outputId": "d1a3f04a-c3fc-4153-952e-607f9e3264e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1204\n",
            "[LightGBM] [Info] Number of data points in the train set: 1700, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000761 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1212\n",
            "[LightGBM] [Info] Number of data points in the train set: 1701, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1218\n",
            "[LightGBM] [Info] Number of data points in the train set: 1701, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1215\n",
            "[LightGBM] [Info] Number of data points in the train set: 1701, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1217\n",
            "[LightGBM] [Info] Number of data points in the train set: 1701, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Classification Report (5-fold CV on training set):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.98      0.98      1655\n",
            "           2       0.87      0.86      0.87       295\n",
            "           3       0.94      0.92      0.93       176\n",
            "\n",
            "    accuracy                           0.96      2126\n",
            "   macro avg       0.93      0.92      0.92      2126\n",
            "weighted avg       0.96      0.96      0.96      2126\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "lgbm = LGBMClassifier(\n",
        "    n_estimators=110,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    random_state=43,\n",
        "    class_weight=\"balanced\"\n",
        ")\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=69)\n",
        "\n",
        "y_pred = cross_val_predict(lgbm, X, y, cv=kf)\n",
        "\n",
        "print(\"\\nClassification Report (5-fold CV on training set):\\n\")\n",
        "print(classification_report(y, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KengQLIsIahq",
        "outputId": "cee178ca-b08d-43d1-cfce-f9f95ecb5fbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report (5-fold CV on training set):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      1655\n",
            "           1       0.90      0.80      0.85       295\n",
            "           2       0.96      0.91      0.94       176\n",
            "\n",
            "    accuracy                           0.95      2126\n",
            "   macro avg       0.94      0.90      0.92      2126\n",
            "weighted avg       0.95      0.95      0.95      2126\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "y_xgb = y.map({1: 0, 2: 1, 3: 2}).values\n",
        "\n",
        "# Compute class weights (balanced: inverse frequency)\n",
        "class_counts = np.bincount(y_xgb)\n",
        "total = len(y_xgb)\n",
        "class_weights = {i: total / (len(class_counts) * count) for i, count in enumerate(class_counts)}\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=120,        # boosting rounds per base model\n",
        "    learning_rate=0.05,\n",
        "    max_depth=20,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=43,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"logloss\",\n",
        "    scale_pos_weight=class_weights\n",
        ")\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=69)\n",
        "y_pred = cross_val_predict(xgb, X, y_xgb, cv=kf)\n",
        "\n",
        "print(\"\\nClassification Report (5-fold CV on training set):\\n\")\n",
        "print(classification_report(y_xgb, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
